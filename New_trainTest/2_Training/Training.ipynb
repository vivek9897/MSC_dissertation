{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OLfzqJfbqeKx"
   },
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IPUrnGo7qn1K"
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 278,
     "status": "ok",
     "timestamp": 1690232675684,
     "user": {
      "displayName": "George Rayment",
      "userId": "08879718775534266561"
     },
     "user_tz": -60
    },
    "id": "nYmFZEvEqaO3",
    "outputId": "f8cf9620-fdd4-4132-9730-808822b2e75d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/vivekkumar/Documents/MSC_dissertation_project/2_Training\n"
     ]
    }
   ],
   "source": [
    "# TODO: replace this with the path to your project\n",
    "%cd /Users/vivekkumar/Documents/MSC_dissertation_project/2_Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 264,
     "status": "ok",
     "timestamp": 1690232676181,
     "user": {
      "displayName": "George Rayment",
      "userId": "08879718775534266561"
     },
     "user_tz": -60
    },
    "id": "AqU_2P4YqtnS",
    "outputId": "509d7f88-d120-4c23-c09a-4e5a17546203"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/vivekkumar/Documents/MSC_dissertation_project/2_Training\n"
     ]
    }
   ],
   "source": [
    "# confirm it works by running this cell and checking the output matched the path in the above cell\n",
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 10648,
     "status": "ok",
     "timestamp": 1690232748226,
     "user": {
      "displayName": "George Rayment",
      "userId": "08879718775534266561"
     },
     "user_tz": -60
    },
    "id": "KQgAxPsCqvgX"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.3\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.2.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip3 install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# install the stable baselines 3 library\n",
    "%pip install stable_baselines3 -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1690232750843,
     "user": {
      "displayName": "George Rayment",
      "userId": "08879718775534266561"
     },
     "user_tz": -60
    },
    "id": "91SXJdyDqyPe"
   },
   "outputs": [],
   "source": [
    "import gymnasium\n",
    "\n",
    "# utils imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# environment imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import os\n",
    "import json\n",
    "import sys\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Polygon\n",
    "\n",
    "# training imports\n",
    "import torch\n",
    "from stable_baselines3 import PPO  # project 4\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "from stable_baselines3.common.callbacks import EvalCallback, StopTrainingOnNoModelImprovement\n",
    "\n",
    "# set seed variable\n",
    "seed = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qpAM92QFqzUY"
   },
   "source": [
    "## Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "executionInfo": {
     "elapsed": 242,
     "status": "ok",
     "timestamp": 1690232800385,
     "user": {
      "displayName": "George Rayment",
      "userId": "08879718775534266561"
     },
     "user_tz": -60
    },
    "id": "_Jlk_SMrq0i_"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# set seeds\n",
    "seed = 42\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "\n",
    "# calculate profit\n",
    "def calculate_profit(position_size, trade_direction, entry_price, exit_price):\n",
    "\n",
    "    # fixed transaction cost\n",
    "    t_cost = 0.0001 * position_size\n",
    "\n",
    "    price_change = (exit_price - entry_price) / entry_price\n",
    "\n",
    "    if trade_direction == 1:\n",
    "        profit = price_change * position_size\n",
    "    elif trade_direction == -1:\n",
    "        profit = -price_change * position_size\n",
    "    else:\n",
    "        return 0\n",
    "    return profit - t_cost\n",
    "\n",
    "# get datasets\n",
    "def get_data(pair, window):\n",
    "\n",
    "    train_df = pd.read_parquet(f'/Users/vivekkumar/Documents/MSC_dissertation_project/New_trainTest/data_1/{pair}/Window_{window}/train.parquet.gzip')\n",
    "    val_df = pd.read_parquet(f'/Users/vivekkumar/Documents/MSC_dissertation_project/New_trainTest/data_1/{pair}/Window_{window}/validation.parquet.gzip')\n",
    "    test_df = pd.read_parquet(f'/Users/vivekkumar/Documents/MSC_dissertation_project/New_trainTest/data_1/{pair}/Window_{window}/test.parquet.gzip')\n",
    "\n",
    "    train_df = train_df.groupby((train_df['Direction_0.00015'].shift() != train_df['Direction_0.00015']).cumsum()).first()\n",
    "    val_df = train_df.groupby((val_df['Direction_0.00015'].shift() != val_df['Direction_0.00015']).cumsum()).first()\n",
    "    # test_df = test_df.groupby((train_df['Direction_0.00015'].shift() != test_df['Direction_0.00015']).cumsum()).first()\n",
    "\n",
    "    train_prices = train_df['DCC_0.00015'].values\n",
    "    val_prices = val_df['DCC_0.00015'].values\n",
    "    test_prices = test_df['DCC_0.00015'].values\n",
    "\n",
    "    train_df = train_df.filter(regex='Direction|DCC')\n",
    "    val_df = val_df.filter(regex='Direction|DCC')\n",
    "    # test_df = test_df.filter(regex='Direction|DCC')\n",
    "\n",
    "    # train_df, val_df, test_df = normalize_dataframes(train_df, val_df, test_df)\n",
    "    # train_df, val_df, test_df = manual_normalise(train_df, val_df, test_df)\n",
    "\n",
    "    train_data = train_df.values\n",
    "    val_data = val_df.values\n",
    "    test_data = test_df.values\n",
    "\n",
    "    data_dict = {\n",
    "        'train_data': train_data,\n",
    "        'train_prices': train_prices,\n",
    "        'val_data': val_data,\n",
    "        'val_prices': val_prices,\n",
    "        'test_data': test_data,\n",
    "        'test_prices': test_prices\n",
    "    }\n",
    "\n",
    "    print(\"------- Data -------\")\n",
    "    print(f\"Train Shape: {train_data.shape}\")\n",
    "    print(f\"Validation Shape: {val_data.shape}\")\n",
    "    print(f\"Test Shape: {test_data.shape}\")\n",
    "\n",
    "    return data_dict\n",
    "\n",
    "# percentage change\n",
    "def pct_change(old_value, new_value):\n",
    "    change = new_value - old_value\n",
    "    percentage_change = (change / old_value)\n",
    "    return percentage_change\n",
    "\n",
    "# shift by n, new start values are replace by np.nan and end values are discarded\n",
    "def shift(array, shift):\n",
    "    return np.concatenate(([np.nan] * shift, array[:-shift]))\n",
    "\n",
    "# rolling window generator, left over events are discarded\n",
    "def rolling_window(df, window_size, shift):\n",
    "    for i in range(0, len(df) - window_size + 1, shift):\n",
    "        yield df.iloc[i:i+window_size]\n",
    "\n",
    "# take train, validation and test sets and normalise based on training data\n",
    "def normalize_dataframes(train_df, val_df, test_df):\n",
    "    # create a MinMaxScaler object\n",
    "    scaler = MinMaxScaler()\n",
    "\n",
    "    # fit the scaler on the train DataFrame\n",
    "    scaler.fit(train_df)\n",
    "\n",
    "    # normalize each DataFrame using the fitted scaler\n",
    "    train_normalized = pd.DataFrame(scaler.transform(train_df), columns=train_df.columns)\n",
    "    val_normalized = pd.DataFrame(scaler.transform(val_df), columns=val_df.columns)\n",
    "    test_normalized = pd.DataFrame(scaler.transform(test_df), columns=test_df.columns)\n",
    "\n",
    "    return train_normalized, val_normalized, test_normalized\n",
    "\n",
    "def manual_normalise(train_df, val_df, test_df):\n",
    "\n",
    "    DC_start_end = train_df[['Start', 'DCC']]\n",
    "    train_transformed = (train_df - train_df.min()) / (train_df.max() - train_df.min())\n",
    "    train_transformed[['Start', 'DCC']] = DC_start_end\n",
    "\n",
    "    DC_start_end = val_df[['Start', 'DCC']]\n",
    "    val_transformed = (val_df - train_df.min()) / (train_df.max() - train_df.min())\n",
    "    val_transformed[['Start', 'DCC']] = DC_start_end\n",
    "\n",
    "    DC_start_end = test_df[['Start', 'DCC']]\n",
    "    test_transformed = (test_df - train_df.min()) / (train_df.max() - train_df.min())\n",
    "    test_transformed[['Start', 'DCC']] = DC_start_end\n",
    "\n",
    "    return train_transformed, val_transformed, test_transformed\n",
    "\n",
    "\n",
    "# trend class\n",
    "class Trend(object):\n",
    "    def __init__(self, direction, DC_start, DCC, OS_end, DC_start_index, DCC_index, OS_end_index):\n",
    "        self.direction, self.DC_start, self.DCC, self.OS_end = direction, DC_start, DCC, OS_end\n",
    "        self.DC_start_index, self.DCC_index, self.OS_end_index = DC_start_index, DCC_index, OS_end_index\n",
    "\n",
    "        self.data_dict = {\n",
    "                'Direction': self.direction,\n",
    "                'Start': round(self.DC_start, 6),\n",
    "                'DCC': round(self.DCC, 6),\n",
    "                'End': round(self.OS_end, 6),\n",
    "                'Start Index': round(self.DC_start_index, 6),\n",
    "                'DCC Index': round(self.DCC_index, 6),\n",
    "                'End Index': round(self.OS_end_index, 6),\n",
    "            }\n",
    "\n",
    "    def __str__(self):\n",
    "        return str(self.data_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PZJWeGpUq9Go"
   },
   "source": [
    "## Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "executionInfo": {
     "elapsed": 260,
     "status": "ok",
     "timestamp": 1690232755160,
     "user": {
      "displayName": "George Rayment",
      "userId": "08879718775534266561"
     },
     "user_tz": -60
    },
    "id": "-Fkba5rwrRlP"
   },
   "outputs": [],
   "source": [
    "with open('/Users/vivekkumar/Documents/MSC_dissertation_project/New_trainTest/params.json', 'r') as f:\n",
    "    params = json.load(f)\n",
    "\n",
    "class DirectionalChangeEnv(gymnasium.Env):\n",
    "    def __init__(self, env_config):\n",
    "\n",
    "        # get data from config\n",
    "        data = env_config['data']\n",
    "        prices = env_config['prices']\n",
    "\n",
    "        self.full_data = data\n",
    "        self.full_prices = prices\n",
    "\n",
    "        # init state params\n",
    "        self.context_length = int(params['training']['context_length'])\n",
    "        self.lag = int(params['training']['lag'])\n",
    "        try:\n",
    "            self.start_index = random.randint(0, len(self.full_data) - (self.context_length + 1))\n",
    "        except:\n",
    "            self.start_index = 0\n",
    "        self.end_index = self.start_index + self.context_length\n",
    "\n",
    "        # init data\n",
    "        self.data = self.full_data[self.start_index: self.end_index]\n",
    "        self.prices = self.full_prices[self.start_index: self.end_index]\n",
    "\n",
    "        # init state\n",
    "        self.i = self.lag - 1\n",
    "        self.state = self.data[0:self.i + 1]\n",
    "        self.price = self.prices[self.i]\n",
    "\n",
    "        # set action and observation space\n",
    "        self.action_space = gymnasium.spaces.Discrete(2)  # buy, sell\n",
    "        self.observation_space = gymnasium.spaces.Box(0, 2, shape=self.state.shape)  # DC start, DC end for last 5 timesteps\n",
    "\n",
    "        # init simulation params\n",
    "        self.n_prices = len(self.data) - self.lag\n",
    "        self.balance = 100\n",
    "        self.entry_price = None\n",
    "        self.position_size = None\n",
    "        self.in_position = 0  # -1 for short, 0 for no, 1 for long\n",
    "        self.trading_log = []\n",
    "\n",
    "    def step(self, action):\n",
    "\n",
    "        self.i += 1\n",
    "        self.n_prices -= 1\n",
    "        self.state = self.data[self.i - (self.lag-1) : self.i + 1]\n",
    "        self.mid_price = self.price\n",
    "\n",
    "        # reward function\n",
    "        if self.in_position == 0:\n",
    "            if action == 0:  #  buy\n",
    "                self.entry_price = self.mid_price  # long at ask price\n",
    "                self.position_size = self.balance\n",
    "                self.in_position = 1\n",
    "                reward = 0\n",
    "            elif action == 1:  # sell\n",
    "                self.entry_price = self.mid_price  # short at bid price\n",
    "                self.position_size = self.balance\n",
    "                self.in_position = -1\n",
    "                reward = 0\n",
    "\n",
    "        elif self.in_position == -1:\n",
    "            if action == 0:  #  buy\n",
    "                profit = calculate_profit(self.position_size, self.in_position,\n",
    "                                          self.entry_price, self.mid_price)  # exit short position at ask price\n",
    "                self.trading_log.append({'Trade Index': self.i,\n",
    "                                         'Position Size': self.position_size,\n",
    "                                         'Trade Type': 'Short',\n",
    "                                         'Entry Price': self.entry_price,\n",
    "                                         'Exit Price': self.mid_price,\n",
    "                                         'Profit': profit})\n",
    "                reward = profit\n",
    "                self.balance += profit\n",
    "                self.in_position = 0\n",
    "                self.position_size = None\n",
    "                self.entry_price = None\n",
    "            elif action == 1:  # sell\n",
    "                reward = 0\n",
    "\n",
    "        elif self.in_position == 1:\n",
    "            if action == 0:  #  buy\n",
    "                reward = 0\n",
    "            elif action == 1:  # sell\n",
    "                profit = calculate_profit(self.position_size, self.in_position,\n",
    "                                          self.entry_price, self.mid_price)  # exit long position as bid price\n",
    "                self.trading_log.append({'Trade Index': self.i,\n",
    "                                         'Position Size': self.position_size,\n",
    "                                         'Trade Type': 'Long',\n",
    "                                         'Entry Price': self.entry_price,\n",
    "                                         'Exit Price': self.mid_price,\n",
    "                                         'Profit': profit})\n",
    "                reward = profit\n",
    "                self.balance += profit\n",
    "                self.in_position = 0\n",
    "                self.position_size = None\n",
    "                self.entry_price = None\n",
    "\n",
    "        if self.n_prices <= 0 or self.balance <= 0:\n",
    "            done = True\n",
    "            if self.in_position != 0:\n",
    "\n",
    "                if self.in_position == -1:\n",
    "                    trade_type = 'Short'\n",
    "                    exit_price = self.mid_price\n",
    "                elif self.in_position == 1:\n",
    "                    trade_type = 'Long'\n",
    "                    exit_price = self.mid_price\n",
    "\n",
    "                profit = calculate_profit(self.position_size, self.in_position,\n",
    "                                            self.entry_price, exit_price)\n",
    "                reward = profit\n",
    "\n",
    "                self.trading_log.append({'Trade Index': self.i,\n",
    "                                         'Position Size': self.position_size,\n",
    "                                         'Trade Type': trade_type,\n",
    "                                         'Entry Price': self.entry_price,\n",
    "                                         'Exit Price': exit_price,\n",
    "                                         'Profit': profit})\n",
    "                self.balance += profit\n",
    "                self.in_position = 0\n",
    "        else:\n",
    "            done = False\n",
    "\n",
    "        info = {'balance': self.balance,\n",
    "                'trading_log': self.trading_log}\n",
    "\n",
    "        return self.state, reward, done, False, info\n",
    "\n",
    "    def reset(self, seed=seed, options=None):\n",
    "\n",
    "        # generate new training set\n",
    "        try:\n",
    "            self.start_index = random.randint(0, len(self.full_data) - (self.context_length + 1))\n",
    "        except:\n",
    "            self.start_index = 0\n",
    "        self.end_index = self.start_index + self.context_length\n",
    "        self.data = self.full_data[self.start_index: self.end_index]\n",
    "        self.prices = self.full_prices[self.start_index: self.end_index]\n",
    "\n",
    "        # reset episode variables\n",
    "        self.i = self.lag - 1\n",
    "        self.state = self.data[0:self.i + 1]\n",
    "        self.price = self.prices[self.i]\n",
    "        self.n_prices = len(self.data) - self.lag\n",
    "        self.balance = 100\n",
    "        self.entry_price = None\n",
    "        self.position_size = None\n",
    "        self.in_position = 0  # -1 for short, 0 for no, 1 for long\n",
    "        self.trading_log = []\n",
    "\n",
    "        return self.state, {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u7zawkuarEpu"
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "executionInfo": {
     "elapsed": 211,
     "status": "ok",
     "timestamp": 1690232871663,
     "user": {
      "displayName": "George Rayment",
      "userId": "08879718775534266561"
     },
     "user_tz": -60
    },
    "id": "UEFMtVPOq8fA"
   },
   "outputs": [],
   "source": [
    "class ModelTrainer(object):\n",
    "    \"\"\"class to run training of model\"\"\"\n",
    "    def __init__(self):\n",
    "\n",
    "        # get data\n",
    "        data_dict = get_data(pair, window)\n",
    "        train_data = data_dict['train_data']\n",
    "        train_prices = data_dict['train_prices']\n",
    "        val_data = data_dict['val_data']\n",
    "        val_prices = data_dict['val_prices']\n",
    "\n",
    "        # configure training parameters\n",
    "        env_config = {\n",
    "                'data': train_data,\n",
    "                'prices': train_prices\n",
    "            }\n",
    "\n",
    "        # configure algorithm\n",
    "        log_path = f\"./Logs/{pair}/Window_{window}\"\n",
    "        env = DirectionalChangeEnv(env_config)\n",
    "        self.model = PPO('MlpPolicy', env, verbose=1, tensorboard_log=log_path)\n",
    "\n",
    "    def save_checkpoint(self):\n",
    "        # save model\n",
    "        model_folder = f'./Models/{pair}/'\n",
    "        self.model.save(model_folder + f'PPO_Window_{window}')\n",
    "        print('model saved')\n",
    "\n",
    "    def train(self):\n",
    "        self.model.learn(total_timesteps=200000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BVtoiPsQrwVP"
   },
   "source": [
    "## Run Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 45680,
     "status": "ok",
     "timestamp": 1690232858399,
     "user": {
      "displayName": "George Rayment",
      "userId": "08879718775534266561"
     },
     "user_tz": -60
    },
    "id": "gkCUDzo1rwCt",
    "outputId": "cd62f7db-1311-4c6a-a410-c55f6f9f1e33"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------- Data -------\n",
      "Train Shape: (103532, 6)\n",
      "Validation Shape: (1076, 6)\n",
      "Test Shape: (13039366, 9)\n",
      "Using cpu device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "Trying to log data to tensorboard but tensorboard is not installed.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[27], line 14\u001b[0m\n\u001b[1;32m     11\u001b[0m trainer \u001b[39m=\u001b[39m ModelTrainer()\n\u001b[1;32m     13\u001b[0m \u001b[39m# train the model\u001b[39;00m\n\u001b[0;32m---> 14\u001b[0m trainer\u001b[39m.\u001b[39;49mtrain()\n\u001b[1;32m     16\u001b[0m \u001b[39m# save model\u001b[39;00m\n\u001b[1;32m     17\u001b[0m trainer\u001b[39m.\u001b[39msave_checkpoint()\n",
      "Cell \u001b[0;32mIn[23], line 30\u001b[0m, in \u001b[0;36mModelTrainer.train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtrain\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m---> 30\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel\u001b[39m.\u001b[39;49mlearn(total_timesteps\u001b[39m=\u001b[39;49m\u001b[39m200000\u001b[39;49m)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/stable_baselines3/ppo/ppo.py:308\u001b[0m, in \u001b[0;36mPPO.learn\u001b[0;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[0m\n\u001b[1;32m    299\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mlearn\u001b[39m(\n\u001b[1;32m    300\u001b[0m     \u001b[39mself\u001b[39m: SelfPPO,\n\u001b[1;32m    301\u001b[0m     total_timesteps: \u001b[39mint\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    306\u001b[0m     progress_bar: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m    307\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m SelfPPO:\n\u001b[0;32m--> 308\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mlearn(\n\u001b[1;32m    309\u001b[0m         total_timesteps\u001b[39m=\u001b[39;49mtotal_timesteps,\n\u001b[1;32m    310\u001b[0m         callback\u001b[39m=\u001b[39;49mcallback,\n\u001b[1;32m    311\u001b[0m         log_interval\u001b[39m=\u001b[39;49mlog_interval,\n\u001b[1;32m    312\u001b[0m         tb_log_name\u001b[39m=\u001b[39;49mtb_log_name,\n\u001b[1;32m    313\u001b[0m         reset_num_timesteps\u001b[39m=\u001b[39;49mreset_num_timesteps,\n\u001b[1;32m    314\u001b[0m         progress_bar\u001b[39m=\u001b[39;49mprogress_bar,\n\u001b[1;32m    315\u001b[0m     )\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/stable_baselines3/common/on_policy_algorithm.py:246\u001b[0m, in \u001b[0;36mOnPolicyAlgorithm.learn\u001b[0;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[0m\n\u001b[1;32m    235\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mlearn\u001b[39m(\n\u001b[1;32m    236\u001b[0m     \u001b[39mself\u001b[39m: SelfOnPolicyAlgorithm,\n\u001b[1;32m    237\u001b[0m     total_timesteps: \u001b[39mint\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    242\u001b[0m     progress_bar: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m    243\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m SelfOnPolicyAlgorithm:\n\u001b[1;32m    244\u001b[0m     iteration \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m--> 246\u001b[0m     total_timesteps, callback \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_setup_learn(\n\u001b[1;32m    247\u001b[0m         total_timesteps,\n\u001b[1;32m    248\u001b[0m         callback,\n\u001b[1;32m    249\u001b[0m         reset_num_timesteps,\n\u001b[1;32m    250\u001b[0m         tb_log_name,\n\u001b[1;32m    251\u001b[0m         progress_bar,\n\u001b[1;32m    252\u001b[0m     )\n\u001b[1;32m    254\u001b[0m     callback\u001b[39m.\u001b[39mon_training_start(\u001b[39mlocals\u001b[39m(), \u001b[39mglobals\u001b[39m())\n\u001b[1;32m    256\u001b[0m     \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39menv \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/stable_baselines3/common/base_class.py:433\u001b[0m, in \u001b[0;36mBaseAlgorithm._setup_learn\u001b[0;34m(self, total_timesteps, callback, reset_num_timesteps, tb_log_name, progress_bar)\u001b[0m\n\u001b[1;32m    431\u001b[0m \u001b[39m# Configure logger's outputs if no logger was passed\u001b[39;00m\n\u001b[1;32m    432\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_custom_logger:\n\u001b[0;32m--> 433\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_logger \u001b[39m=\u001b[39m utils\u001b[39m.\u001b[39;49mconfigure_logger(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mverbose, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtensorboard_log, tb_log_name, reset_num_timesteps)\n\u001b[1;32m    435\u001b[0m \u001b[39m# Create eval callback if needed\u001b[39;00m\n\u001b[1;32m    436\u001b[0m callback \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_init_callback(callback, progress_bar)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/stable_baselines3/common/utils.py:199\u001b[0m, in \u001b[0;36mconfigure_logger\u001b[0;34m(verbose, tensorboard_log, tb_log_name, reset_num_timesteps)\u001b[0m\n\u001b[1;32m    196\u001b[0m save_path, format_strings \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m, [\u001b[39m\"\u001b[39m\u001b[39mstdout\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m    198\u001b[0m \u001b[39mif\u001b[39;00m tensorboard_log \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m SummaryWriter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 199\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mImportError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mTrying to log data to tensorboard but tensorboard is not installed.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    201\u001b[0m \u001b[39mif\u001b[39;00m tensorboard_log \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m SummaryWriter \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    202\u001b[0m     latest_run_id \u001b[39m=\u001b[39m get_latest_run_id(tensorboard_log, tb_log_name)\n",
      "\u001b[0;31mImportError\u001b[0m: Trying to log data to tensorboard but tensorboard is not installed."
     ]
    }
   ],
   "source": [
    "# set seeds - this is to ensure reproducibility\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "# set script variables\n",
    "pair = str('AUDUSD')  # run for all pairs: AUDUSD, EURGBP, EURUSD and USDCAD\n",
    "window = int(0)  # run for all windows\n",
    "\n",
    "# create experiment\n",
    "trainer = ModelTrainer()\n",
    "\n",
    "# train the model\n",
    "trainer.train()\n",
    "\n",
    "# save model\n",
    "trainer.save_checkpoint()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyP/Ogq9M68UbctjdB11WIvW",
   "mount_file_id": "1UCljSWPt8YiX93e4eVQ9TasLviBhx_gw",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
