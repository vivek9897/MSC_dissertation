{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OLfzqJfbqeKx"
   },
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IPUrnGo7qn1K"
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 278,
     "status": "ok",
     "timestamp": 1690232675684,
     "user": {
      "displayName": "George Rayment",
      "userId": "08879718775534266561"
     },
     "user_tz": -60
    },
    "id": "nYmFZEvEqaO3",
    "outputId": "f8cf9620-fdd4-4132-9730-808822b2e75d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 2] No such file or directory: '/DocumentsMSC_dissertation_project2_Training'\n",
      "/Users/vivekkumar/Documents/MSC_dissertation_project/New_trainTest/2_Training\n"
     ]
    }
   ],
   "source": [
    "# TODO: replace this with the path to your project\n",
    "%cd /DocumentsMSC_dissertation_project2_Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 264,
     "status": "ok",
     "timestamp": 1690232676181,
     "user": {
      "displayName": "George Rayment",
      "userId": "08879718775534266561"
     },
     "user_tz": -60
    },
    "id": "AqU_2P4YqtnS",
    "outputId": "509d7f88-d120-4c23-c09a-4e5a17546203"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/MyDrive/MScProjects/Project_3/2_Training\n"
     ]
    }
   ],
   "source": [
    "# confirm it works by running this cell and checking the output matched the path in the above cell\n",
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "executionInfo": {
     "elapsed": 10648,
     "status": "ok",
     "timestamp": 1690232748226,
     "user": {
      "displayName": "George Rayment",
      "userId": "08879718775534266561"
     },
     "user_tz": -60
    },
    "id": "KQgAxPsCqvgX"
   },
   "outputs": [],
   "source": [
    "# install the stable baselines 3 library\n",
    "!pip install stable_baselines3 -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1690232750843,
     "user": {
      "displayName": "George Rayment",
      "userId": "08879718775534266561"
     },
     "user_tz": -60
    },
    "id": "91SXJdyDqyPe"
   },
   "outputs": [],
   "source": [
    "import gymnasium\n",
    "\n",
    "# utils imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# environment imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import os\n",
    "import json\n",
    "import sys\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Polygon\n",
    "\n",
    "# training imports\n",
    "import torch\n",
    "from stable_baselines3 import PPO  # project 4\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "from stable_baselines3.common.callbacks import EvalCallback, StopTrainingOnNoModelImprovement\n",
    "\n",
    "# set seed variable\n",
    "seed = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qpAM92QFqzUY"
   },
   "source": [
    "## Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "executionInfo": {
     "elapsed": 242,
     "status": "ok",
     "timestamp": 1690232800385,
     "user": {
      "displayName": "George Rayment",
      "userId": "08879718775534266561"
     },
     "user_tz": -60
    },
    "id": "_Jlk_SMrq0i_"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# set seeds\n",
    "seed = 42\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "\n",
    "# calculate profit\n",
    "def calculate_profit(position_size, trade_direction, entry_price, exit_price):\n",
    "\n",
    "    # fixed transaction cost\n",
    "    t_cost = 0.0001 * position_size\n",
    "\n",
    "    price_change = (exit_price - entry_price) / entry_price\n",
    "\n",
    "    if trade_direction == 1:\n",
    "        profit = price_change * position_size\n",
    "    elif trade_direction == -1:\n",
    "        profit = -price_change * position_size\n",
    "    else:\n",
    "        return 0\n",
    "    return profit - t_cost\n",
    "\n",
    "# get datasets\n",
    "def get_data(pair, window):\n",
    "\n",
    "    train_df = pd.read_parquet(f'../1_Data/{pair}/Window_{window}/train.parquet.gzip')\n",
    "    val_df = pd.read_parquet(f'../1_Data/{pair}/Window_{window}/validation.parquet.gzip')\n",
    "    test_df = pd.read_parquet(f'../1_Data/{pair}/Window_{window}/test.parquet.gzip')\n",
    "\n",
    "    train_df = train_df.groupby((train_df['Direction_0.00015'].shift() != train_df['Direction_0.00015']).cumsum()).first()\n",
    "    val_df = train_df.groupby((val_df['Direction_0.00015'].shift() != val_df['Direction_0.00015']).cumsum()).first()\n",
    "    # test_df = test_df.groupby((train_df['Direction_0.00015'].shift() != test_df['Direction_0.00015']).cumsum()).first()\n",
    "\n",
    "    train_prices = train_df['DCC_0.00015'].values\n",
    "    val_prices = val_df['DCC_0.00015'].values\n",
    "    test_prices = test_df['DCC_0.00015'].values\n",
    "\n",
    "    train_df = train_df.filter(regex='Direction|DCC')\n",
    "    val_df = val_df.filter(regex='Direction|DCC')\n",
    "    # test_df = test_df.filter(regex='Direction|DCC')\n",
    "\n",
    "    # train_df, val_df, test_df = normalize_dataframes(train_df, val_df, test_df)\n",
    "    # train_df, val_df, test_df = manual_normalise(train_df, val_df, test_df)\n",
    "\n",
    "    train_data = train_df.values\n",
    "    val_data = val_df.values\n",
    "    test_data = test_df.values\n",
    "\n",
    "    data_dict = {\n",
    "        'train_data': train_data,\n",
    "        'train_prices': train_prices,\n",
    "        'val_data': val_data,\n",
    "        'val_prices': val_prices,\n",
    "        'test_data': test_data,\n",
    "        'test_prices': test_prices\n",
    "    }\n",
    "\n",
    "    print(\"------- Data -------\")\n",
    "    print(f\"Train Shape: {train_data.shape}\")\n",
    "    print(f\"Validation Shape: {val_data.shape}\")\n",
    "    print(f\"Test Shape: {test_data.shape}\")\n",
    "\n",
    "    return data_dict\n",
    "\n",
    "# percentage change\n",
    "def pct_change(old_value, new_value):\n",
    "    change = new_value - old_value\n",
    "    percentage_change = (change / old_value)\n",
    "    return percentage_change\n",
    "\n",
    "# shift by n, new start values are replace by np.nan and end values are discarded\n",
    "def shift(array, shift):\n",
    "    return np.concatenate(([np.nan] * shift, array[:-shift]))\n",
    "\n",
    "# rolling window generator, left over events are discarded\n",
    "def rolling_window(df, window_size, shift):\n",
    "    for i in range(0, len(df) - window_size + 1, shift):\n",
    "        yield df.iloc[i:i+window_size]\n",
    "\n",
    "# take train, validation and test sets and normalise based on training data\n",
    "def normalize_dataframes(train_df, val_df, test_df):\n",
    "    # create a MinMaxScaler object\n",
    "    scaler = MinMaxScaler()\n",
    "\n",
    "    # fit the scaler on the train DataFrame\n",
    "    scaler.fit(train_df)\n",
    "\n",
    "    # normalize each DataFrame using the fitted scaler\n",
    "    train_normalized = pd.DataFrame(scaler.transform(train_df), columns=train_df.columns)\n",
    "    val_normalized = pd.DataFrame(scaler.transform(val_df), columns=val_df.columns)\n",
    "    test_normalized = pd.DataFrame(scaler.transform(test_df), columns=test_df.columns)\n",
    "\n",
    "    return train_normalized, val_normalized, test_normalized\n",
    "\n",
    "def manual_normalise(train_df, val_df, test_df):\n",
    "\n",
    "    DC_start_end = train_df[['Start', 'DCC']]\n",
    "    train_transformed = (train_df - train_df.min()) / (train_df.max() - train_df.min())\n",
    "    train_transformed[['Start', 'DCC']] = DC_start_end\n",
    "\n",
    "    DC_start_end = val_df[['Start', 'DCC']]\n",
    "    val_transformed = (val_df - train_df.min()) / (train_df.max() - train_df.min())\n",
    "    val_transformed[['Start', 'DCC']] = DC_start_end\n",
    "\n",
    "    DC_start_end = test_df[['Start', 'DCC']]\n",
    "    test_transformed = (test_df - train_df.min()) / (train_df.max() - train_df.min())\n",
    "    test_transformed[['Start', 'DCC']] = DC_start_end\n",
    "\n",
    "    return train_transformed, val_transformed, test_transformed\n",
    "\n",
    "\n",
    "# trend class\n",
    "class Trend(object):\n",
    "    def __init__(self, direction, DC_start, DCC, OS_end, DC_start_index, DCC_index, OS_end_index):\n",
    "        self.direction, self.DC_start, self.DCC, self.OS_end = direction, DC_start, DCC, OS_end\n",
    "        self.DC_start_index, self.DCC_index, self.OS_end_index = DC_start_index, DCC_index, OS_end_index\n",
    "\n",
    "        self.data_dict = {\n",
    "                'Direction': self.direction,\n",
    "                'Start': round(self.DC_start, 6),\n",
    "                'DCC': round(self.DCC, 6),\n",
    "                'End': round(self.OS_end, 6),\n",
    "                'Start Index': round(self.DC_start_index, 6),\n",
    "                'DCC Index': round(self.DCC_index, 6),\n",
    "                'End Index': round(self.OS_end_index, 6),\n",
    "            }\n",
    "\n",
    "    def __str__(self):\n",
    "        return str(self.data_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PZJWeGpUq9Go"
   },
   "source": [
    "## Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "executionInfo": {
     "elapsed": 260,
     "status": "ok",
     "timestamp": 1690232755160,
     "user": {
      "displayName": "George Rayment",
      "userId": "08879718775534266561"
     },
     "user_tz": -60
    },
    "id": "-Fkba5rwrRlP"
   },
   "outputs": [],
   "source": [
    "with open('../params.json', 'r') as f:\n",
    "    params = json.load(f)\n",
    "\n",
    "class DirectionalChangeEnv(gymnasium.Env):\n",
    "    def __init__(self, env_config):\n",
    "\n",
    "        # get data from config\n",
    "        data = env_config['data']\n",
    "        prices = env_config['prices']\n",
    "\n",
    "        self.full_data = data\n",
    "        self.full_prices = prices\n",
    "\n",
    "        # init state params\n",
    "        self.context_length = int(params['training']['context_length'])\n",
    "        self.lag = int(params['training']['lag'])\n",
    "        try:\n",
    "            self.start_index = random.randint(0, len(self.full_data) - (self.context_length + 1))\n",
    "        except:\n",
    "            self.start_index = 0\n",
    "        self.end_index = self.start_index + self.context_length\n",
    "\n",
    "        # init data\n",
    "        self.data = self.full_data[self.start_index: self.end_index]\n",
    "        self.prices = self.full_prices[self.start_index: self.end_index]\n",
    "\n",
    "        # init state\n",
    "        self.i = self.lag - 1\n",
    "        self.state = self.data[0:self.i + 1]\n",
    "        self.price = self.prices[self.i]\n",
    "\n",
    "        # set action and observation space\n",
    "        self.action_space = gymnasium.spaces.Discrete(2)  # buy, sell\n",
    "        self.observation_space = gymnasium.spaces.Box(0, 2, shape=self.state.shape)  # DC start, DC end for last 5 timesteps\n",
    "\n",
    "        # init simulation params\n",
    "        self.n_prices = len(self.data) - self.lag\n",
    "        self.balance = 100\n",
    "        self.entry_price = None\n",
    "        self.position_size = None\n",
    "        self.in_position = 0  # -1 for short, 0 for no, 1 for long\n",
    "        self.trading_log = []\n",
    "\n",
    "    def step(self, action):\n",
    "\n",
    "        self.i += 1\n",
    "        self.n_prices -= 1\n",
    "        self.state = self.data[self.i - (self.lag-1) : self.i + 1]\n",
    "        self.mid_price = self.price\n",
    "\n",
    "        # reward function\n",
    "        if self.in_position == 0:\n",
    "            if action == 0:  #  buy\n",
    "                self.entry_price = self.mid_price  # long at ask price\n",
    "                self.position_size = self.balance\n",
    "                self.in_position = 1\n",
    "                reward = 0\n",
    "            elif action == 1:  # sell\n",
    "                self.entry_price = self.mid_price  # short at bid price\n",
    "                self.position_size = self.balance\n",
    "                self.in_position = -1\n",
    "                reward = 0\n",
    "\n",
    "        elif self.in_position == -1:\n",
    "            if action == 0:  #  buy\n",
    "                profit = calculate_profit(self.position_size, self.in_position,\n",
    "                                          self.entry_price, self.mid_price)  # exit short position at ask price\n",
    "                self.trading_log.append({'Trade Index': self.i,\n",
    "                                         'Position Size': self.position_size,\n",
    "                                         'Trade Type': 'Short',\n",
    "                                         'Entry Price': self.entry_price,\n",
    "                                         'Exit Price': self.mid_price,\n",
    "                                         'Profit': profit})\n",
    "                reward = profit\n",
    "                self.balance += profit\n",
    "                self.in_position = 0\n",
    "                self.position_size = None\n",
    "                self.entry_price = None\n",
    "            elif action == 1:  # sell\n",
    "                reward = 0\n",
    "\n",
    "        elif self.in_position == 1:\n",
    "            if action == 0:  #  buy\n",
    "                reward = 0\n",
    "            elif action == 1:  # sell\n",
    "                profit = calculate_profit(self.position_size, self.in_position,\n",
    "                                          self.entry_price, self.mid_price)  # exit long position as bid price\n",
    "                self.trading_log.append({'Trade Index': self.i,\n",
    "                                         'Position Size': self.position_size,\n",
    "                                         'Trade Type': 'Long',\n",
    "                                         'Entry Price': self.entry_price,\n",
    "                                         'Exit Price': self.mid_price,\n",
    "                                         'Profit': profit})\n",
    "                reward = profit\n",
    "                self.balance += profit\n",
    "                self.in_position = 0\n",
    "                self.position_size = None\n",
    "                self.entry_price = None\n",
    "\n",
    "        if self.n_prices <= 0 or self.balance <= 0:\n",
    "            done = True\n",
    "            if self.in_position != 0:\n",
    "\n",
    "                if self.in_position == -1:\n",
    "                    trade_type = 'Short'\n",
    "                    exit_price = self.mid_price\n",
    "                elif self.in_position == 1:\n",
    "                    trade_type = 'Long'\n",
    "                    exit_price = self.mid_price\n",
    "\n",
    "                profit = calculate_profit(self.position_size, self.in_position,\n",
    "                                            self.entry_price, exit_price)\n",
    "                reward = profit\n",
    "\n",
    "                self.trading_log.append({'Trade Index': self.i,\n",
    "                                         'Position Size': self.position_size,\n",
    "                                         'Trade Type': trade_type,\n",
    "                                         'Entry Price': self.entry_price,\n",
    "                                         'Exit Price': exit_price,\n",
    "                                         'Profit': profit})\n",
    "                self.balance += profit\n",
    "                self.in_position = 0\n",
    "        else:\n",
    "            done = False\n",
    "\n",
    "        info = {'balance': self.balance,\n",
    "                'trading_log': self.trading_log}\n",
    "\n",
    "        return self.state, reward, done, False, info\n",
    "\n",
    "    def reset(self, seed=seed, options=None):\n",
    "\n",
    "        # generate new training set\n",
    "        try:\n",
    "            self.start_index = random.randint(0, len(self.full_data) - (self.context_length + 1))\n",
    "        except:\n",
    "            self.start_index = 0\n",
    "        self.end_index = self.start_index + self.context_length\n",
    "        self.data = self.full_data[self.start_index: self.end_index]\n",
    "        self.prices = self.full_prices[self.start_index: self.end_index]\n",
    "\n",
    "        # reset episode variables\n",
    "        self.i = self.lag - 1\n",
    "        self.state = self.data[0:self.i + 1]\n",
    "        self.price = self.prices[self.i]\n",
    "        self.n_prices = len(self.data) - self.lag\n",
    "        self.balance = 100\n",
    "        self.entry_price = None\n",
    "        self.position_size = None\n",
    "        self.in_position = 0  # -1 for short, 0 for no, 1 for long\n",
    "        self.trading_log = []\n",
    "\n",
    "        return self.state, {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u7zawkuarEpu"
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "executionInfo": {
     "elapsed": 211,
     "status": "ok",
     "timestamp": 1690232871663,
     "user": {
      "displayName": "George Rayment",
      "userId": "08879718775534266561"
     },
     "user_tz": -60
    },
    "id": "UEFMtVPOq8fA"
   },
   "outputs": [],
   "source": [
    "class ModelTrainer(object):\n",
    "    \"\"\"class to run training of model\"\"\"\n",
    "    def __init__(self):\n",
    "\n",
    "        # get data\n",
    "        data_dict = get_data(pair, window)\n",
    "        train_data = data_dict['train_data']\n",
    "        train_prices = data_dict['train_prices']\n",
    "        val_data = data_dict['val_data']\n",
    "        val_prices = data_dict['val_prices']\n",
    "\n",
    "        # configure training parameters\n",
    "        env_config = {\n",
    "                'data': train_data,\n",
    "                'prices': train_prices\n",
    "            }\n",
    "\n",
    "        # configure algorithm\n",
    "        log_path = f\"./Logs/{pair}/Window_{window}\"\n",
    "        env = DirectionalChangeEnv(env_config)\n",
    "        self.model = PPO('MlpPolicy', env, verbose=1, tensorboard_log=log_path)\n",
    "\n",
    "    def save_checkpoint(self):\n",
    "        # save model\n",
    "        model_folder = f'./Models/{pair}/'\n",
    "        self.model.save(model_folder + f'PPO_Window_{window}')\n",
    "        print('model saved')\n",
    "\n",
    "    def train(self):\n",
    "        self.model.learn(total_timesteps=200000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BVtoiPsQrwVP"
   },
   "source": [
    "## Run Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 45680,
     "status": "ok",
     "timestamp": 1690232858399,
     "user": {
      "displayName": "George Rayment",
      "userId": "08879718775534266561"
     },
     "user_tz": -60
    },
    "id": "gkCUDzo1rwCt",
    "outputId": "cd62f7db-1311-4c6a-a410-c55f6f9f1e33"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------- Data -------\n",
      "Train Shape: (103532, 6)\n",
      "Validation Shape: (1076, 6)\n",
      "Test Shape: (13039366, 9)\n",
      "Using cpu device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "Logging to ./Logs/AUDUSD/Window_0/PPO_3\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 995      |\n",
      "|    ep_rew_mean     | -3.28    |\n",
      "| time/              |          |\n",
      "|    fps             | 376      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 5        |\n",
      "|    total_timesteps | 2048     |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 995         |\n",
      "|    ep_rew_mean          | -3.26       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 288         |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 14          |\n",
      "|    total_timesteps      | 4096        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010164982 |\n",
      "|    clip_fraction        | 0.0495      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.686      |\n",
      "|    explained_variance   | -12.2       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0223     |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | -0.00503    |\n",
      "|    value_loss           | 0.00722     |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 995          |\n",
      "|    ep_rew_mean          | -3.25        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 293          |\n",
      "|    iterations           | 3            |\n",
      "|    time_elapsed         | 20           |\n",
      "|    total_timesteps      | 6144         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0074907057 |\n",
      "|    clip_fraction        | 0.0279       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.674       |\n",
      "|    explained_variance   | -6.56        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.0119       |\n",
      "|    n_updates            | 20           |\n",
      "|    policy_gradient_loss | -0.00538     |\n",
      "|    value_loss           | 0.00109      |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 995         |\n",
      "|    ep_rew_mean          | -3.25       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 270         |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 30          |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005082385 |\n",
      "|    clip_fraction        | 0.028       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.668      |\n",
      "|    explained_variance   | -4.24       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00829     |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.00256    |\n",
      "|    value_loss           | 0.000532    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 995         |\n",
      "|    ep_rew_mean          | -3.25       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 275         |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 37          |\n",
      "|    total_timesteps      | 10240       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009877652 |\n",
      "|    clip_fraction        | 0.0588      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.662      |\n",
      "|    explained_variance   | -2.43       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00957     |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.00682    |\n",
      "|    value_loss           | 0.000361    |\n",
      "-----------------------------------------\n",
      "model saved\n"
     ]
    }
   ],
   "source": [
    "# set seeds - this is to ensure reproducibility\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "# set script variables\n",
    "pair = str('AUDUSD')  # run for all pairs: AUDUSD, EURGBP, EURUSD and USDCAD\n",
    "window = int(0)  # run for all windows\n",
    "\n",
    "# create experiment\n",
    "trainer = ModelTrainer()\n",
    "\n",
    "# train the model\n",
    "trainer.train()\n",
    "\n",
    "# save model\n",
    "trainer.save_checkpoint()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyP/Ogq9M68UbctjdB11WIvW",
   "mount_file_id": "1UCljSWPt8YiX93e4eVQ9TasLviBhx_gw",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
